---
title: "ollama + AnythingLLM 本地部署 deepseek-r1 和知识库"
date: 2025-1-28 12:00:00 +0800
categories: [tools]     
---

deepseek R1火了，而且开源，跟个风拉个本地模型玩玩。

## 本地部署大模型
开源大模型的获取途径其实挺多的，但为了方便，这里使用ollama来管理大模型。

大模型有一个比较重要的指标是参数数量，比如deepseek-r1就有1.5b、7b、8b、14b、32b、70b和671b这些版本的，b表示billion，671b就是6710亿参数，换算过来显存得4、500个gb才能跑动，本地部署显然不现实。笔者的笔记本上装的是4060，显存8gb，看了看测评决定玩7b的蒸馏版。

蒸馏版参数少了很多，能力肯定不如完整版的，所以只能是玩玩，后面觉得有必要可以换API用满血版的。

### 下载ollama
在[官网](https://ollama.com/)下载，下载源是github上的，可能需要*修炼轻功*才能正常下载。

目前(25.1.21)，ollama拉下来的模型默认安装在C盘，这对于笔者这样C盘红了的很不友好。可以按如下步骤更改模型安装位置：

- 正常安装；
- 找到Ollama安装目录，目前是安装在默认路径下的。去`~\AppData\Local\Programs`(~请自行展开)文件夹中找到Ollama文件夹，将其移动至别的盘，如`D:\program`；
- 将环境变量中Path里的`~\AppData\Local\Programs`改为`D:\program`；
- 添加一个`OLLAMA_MODELS`环境变量，值为存放大模型的目录，如`D:\ollama\models`。

完成后，在cmd中检查环境变量设置是否成功：
```bat
set
```

或者
```bat
echo %OLLAMA_MODELS%
```

### 安装大模型
使用ollama run安装大模型，可以指定参数数量，例如：
```bat
ollama run llama3.1:8b 
ollama run deepseek-r1:7b
```

使用ollama list列出本地大模型：
```
(base) PS D:> ollama list
NAME              ID              SIZE      MODIFIED
gemma2:9b         ff02c3702f32    5.4 GB    20 minutes ago
llama3.1:8b       46e0c10c039e    4.9 GB    38 minutes ago
deepseek-r1:7b    0a8c26691023    4.7 GB    59 minutes ago
```

运行命令和安装命令是一样的：
```bat
ollama run deepseek-r1:7b
```

本地跑的小模型能力有限，做不到完整版那样精通所有语言，所以如果想用中文对话的话，llama3.1很菜，gemma2也感觉一般，不如qwen和deepseek好。

## 设置知识库

为模型设置知识库可以提高正确回答的几率，目前有AnythingLLM和Dify等几个选择。稍微看了一些教程，觉得AnythingLLM比较简单，因此使用AnythingLLM来入门。

在[官网](https://anythingllm.com/desktop)下载AnythingLLM并安装。安装时要下载ollama lib，虽然不是必要的，但如果网络抽风要龟速下好久，所以安装时要么彻底关掉网络要么确保你能顺利下载，不然会安很久很久。

安装完毕后不要急着打开AnythingLLM，先确保ollama在运行。使用命令
```bat
ollama serve
```

完成后打开AnythingLLM，新建一个工作区，名称随便填。可以看到工作区选项卡上有↑上传和⚙设置两个按钮，对应知识库设置和大模型设置。

### 知识库设置
点击↑，弹出上传页面。可以上传文本文件，md或者PDF等格式。把上传的文件点击move to workspace加入工作区，点击save and embed开始转换成向量。转换完毕后，大模型就可以读取你提供的文本了。

### 大模型设置
点击⚙打开设置页面，这里的设置完毕后需要点击底部的update workspace才能保存。

在聊天设置里把LLM提供商改为ollama，此时应当自动加载出来ollama模型选项。选择deepseek-r1:7b或者一个顺眼的模型。下面还有一个关键的聊天模式设置，分为聊天和查询两种：
- 聊天：大模型在知识库找不到目标信息时会根据模型本身的知识库来回答，如果模型本身也找不到资料，则可能给你编一堆乱七八糟的东西出来。
- 查询：严格按照知识库里的知识回答，知识库里找不到的问题没法回答。

对于一些学术问题，给他喂几个综述进去再问可以显著提高回答质量，而且还能给出来引文：
![](https://pub-ec46b9a843f44891acf04d27fddf97e0.r2.dev/2025/02/20250204023703.png)

我这里随便喂的论文，回答可能有点偏向论文内容。但对比直接问得到的幽默结果，显然可以发现喂了论文的回答要强N<sub>A</sub>倍(顺便一提，这个回答里的Compound International System似乎是模型自己编的，至少我没搜到)：
```
(base) PS D:\> ollama run deepseek-r1:7b
>>> CIS(D)是什么
<think>

</think>

CIS(D) 是“Compound International System”的简称，指由联合国教科文组织（ UNESCO ）设立的 18 套国际课程体系之一。该体系旨在为不同国家的学生提供统一的教育标准和课程安排。

### 核心特点：
1. **语言与文化**：强调母语学习和文化背景理解。
2. **年龄分类**：按学生年龄设计课程，确保学习内容适合学生的认知水平。
3. **模块化结构**：课程分为多个模块，涵盖不同学科领域。
4. **国际通用性**：适用于全球多个国家的学生。

### 适用范围：
CIS(D) 适用于 6 至 17 岁的青少年，在全球多国教育体系中推广。学生通过学习该课程可获得统一的文凭，便于在不同国家转换学分或申请教育机会。

### 结构特点：
- **初级课程**：涵盖语言、数学等基础科目。
- **高级课程**：包括自然科学、社会科学等领域，设置详细的学习路径。
- **职业准备**：提供职业发展相关的课程内容。

CIS(D) 的目标是促进全球教育公平和可及性，为学生提供一致且高质量的教育体验。
```

